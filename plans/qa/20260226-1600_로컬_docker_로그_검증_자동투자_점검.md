# 로컬 Docker 컨테이너 로그 검증 및 자동투자 점검 계획

**작성일시**: 2026-02-26  
**목적**: 로컬 Docker Compose 풀스택의 컨테이너별 **전체 로그**를 직접 조회·분석하여 자동투자 배치 정상 여부를 확인하고, 이상 시 원인 분석 및 **Shrimp Task Manager MCP**를 통한 task 단위 수정 개발을 수행한다.

---

## 1. 대상 환경

- **Compose 파일**: [investment-infra/docker-compose.local-full.yml](../../investment-infra/docker-compose.local-full.yml)
- **컨테이너** (7개): `investment-timescaledb`, `investment-redis`, `investment-backend`, `investment-prediction-service`, `investment-data-collector`, `investment-frontend`, `investment-nginx-local`
- **로그 (영구 보관)**  
  - **방법 A**: 모든 서비스 `logging: json-file`, `max-size: 100m`, `max-file: 5` → 컨테이너당 5개 로테이션.  
  - **방법 B**: backend `./logs/backend:/LOG` 볼륨 → Spring Boot 파일 로그가 호스트 `investment-infra/logs/backend/` 에 영구 보관 (down 해도 유지).
- **로그 조회**: `docker compose -f docker-compose.local-full.yml logs <서비스명>` 또는 backend는 호스트 `logs/backend/investment-choi.log` (및 로테이트 파일) 직접 열기.

---

## 2. 전체 로그 조회 수행 결과 (2026-02-26 기준)

### 2.1 조회 명령 및 결과 요약

| 서비스 | 명령 | 결과 |
|--------|------|------|
| backend | `docker compose -f docker-compose.local-full.yml logs backend` | **전체 약 6,345줄** (기동~현재) |
| timescaledb | `docker compose -f docker-compose.local-full.yml logs timescaledb` | 전체 약 932줄 (파일로 저장됨) |
| redis | 동일 방식 | 정상 기동, AOF 저장 성공 반복 |
| prediction-service | 동일 방식 | Uvicorn 8000 기동 완료, 요청 로그 없음 |
| data-collector | 동일 방식 | Uvicorn 8001 기동, `POST /us-daily` 200 OK 수신 |
| frontend | 동일 방식 | nginx worker 기동, `/dashboard`, `/assets/*` 200 |
| nginx | 동일 방식 | proxy 200, 일부 `[warn]` upstream buffered to temp file (대용량 JS 정상) |

### 2.2 Backend 로그 분석 결과 (정상)

- **기동**: Spring Boot 3.2.2, profile `local`, HikariPool·Flyway(스키마 33)·JPA 초기화 완료.
- **배치 스케줄 등록**: `BatchJobScheduler`에서 아래 Job 모두 스케줄 등록됨.
  - trading-portfolio-generator (09:00), short/medium/long-term-strategy-executor, krx/us-daily-collector, factor-calculation (08:00), **auto-buy (09:10)**, pipeline-exit (5분마다 09~15시), fill-confirmation / unfilled-order-check (매분), risk-event-alert (10분마다 09~15시), daily-pnl (16:05), intraday-breakout, strategy-governance-check 등.
- **실행 로그 (이번 기동 구간)**:
  - `fill-confirmation`, `unfilled-order-check`: 매분 launch → COMPLETED.
  - `pipeline-exit`: 15:05 등 시점 launch → COMPLETED.
  - `risk-event-alert`: 15:10 launch → COMPLETED.
- **WARN**: BeanPostProcessor(jobRegistry), Flyway PostgreSQL 16 미검증, Hibernate dialect 명시 불필요, generated security password (개발용). 동작에는 문제 없음.
- **ERROR**: 없음.
- **참고**: Backend 컨테이너는 조회 시점 기준 약 29분 전 재시작되어, **09:10 auto-buy** 실행 로그는 이번 기동 로그에는 없음. 자동투자 ON 계좌 유무·파이프라인 스킵 메시지는 09:10 실행 시에만 출력되므로, 해당 시간대 로그가 필요하면 Backend 재시작 전 로그 또는 다음 09:10 실행 후 로그로 확인 필요.

### 2.4 재시작 전 Backend 로그 복구 시도 결과 (2026-02-26)

- **확인한 것**  
  - `docker ps -a --filter "name=investment-backend"`: 현재 동작 중인 컨테이너 1개만 존재. 재시작 시 **컨테이너가 재생성**(replace)된 경우라 이전 컨테이너는 이미 삭제되어 `docker logs <이전ID>` 불가.  
  - `investment-infra/logs-backup/`: **20260226** 폴더만 있음(당일 백업 스크립트 테스트분). 25일·24일 등 재시작 이전 날짜 스냅샷 없음.  
  - Docker 로그 파일 경로(`docker inspect … LogPath`)는 Docker VM(WSL2/Hyper-V) 내부라 Windows 호스트에서 직접 접근 불가. 삭제된 컨테이너의 로그 디렉터리는 Docker가 제거 시 함께 삭제함.
- **결론**: **이번 재시작(26일 14:59) 이전의 backend 로그는 복구할 수 없음.** 재시작 전 구간 분석은 불가하고, 현재 가용한 로그(재시작 이후 ~현재)만으로 2.2·5절 분석이 유효함.

### 2.3 기타 컨테이너

- **TimescaleDB**: healthcheck·연결 정상. (상세는 저장된 로그 파일 참조)
- **Redis**: 정상 기동, 주기적 RDB/AOF 저장 성공.
- **prediction-service / data-collector**: Backend가 호출 가능한 상태. data-collector는 `POST /us-daily` 200 응답 기록됨.
- **frontend / nginx**: 200 응답, 대용량 asset 시 proxy_temp 경고만 있음 (정상).

---

## 3. 로그 조회 방법 (실행 시 준수 사항)

- **전체 로그만 사용**: `--tail` 등 줄 제한 없이 아래로 조회.
  ```powershell
  cd d:\works\pjt\auto-investment-project\investment-infra
  docker compose -f docker-compose.local-full.yml logs backend
  docker compose -f docker-compose.local-full.yml logs timescaledb
  docker compose -f docker-compose.local-full.yml logs redis
  docker compose -f docker-compose.local-full.yml logs prediction-service
  docker compose -f docker-compose.local-full.yml logs data-collector
  docker compose -f docker-compose.local-full.yml logs frontend
  docker compose -f docker-compose.local-full.yml logs nginx
  ```
- **저장이 필요할 때**: `... logs backend 2>&1 | Out-File -FilePath plans\qa\reports\backend-full.log -Encoding utf8` (디렉터리 미존재 시 먼저 생성).
- **일일 자동 백업**: 매일 03:00(KST)에 로그를 백업하려면 `investment-infra/scripts/register-log-backup-task.ps1` 를 한 번 실행해 작업 스케줄을 등록한다. 백업은 `investment-infra/logs-backup/YYYYMMDD/` 에 저장되며 30일 초과 분은 자동 삭제된다. ([13-manual-operator-tasks.md §1.8](../../investment-backend/docs/06-deployment/13-manual-operator-tasks.md#18-로컬-docker-compose--로그-일일-백업-작업-스케줄-등록) 참조.)

#### 재시작 전 로그를 찾는 방법 (앞으로 적용)

| 방법 | 설명 |
|------|------|
| **방법 B (영구 볼륨)** | backend에 `./logs/backend:/LOG` 적용 후에는 Spring Boot가 호스트 `logs/backend/` 에 직접 기록. **재시작·down 해도 파일은 유지**되므로, 재시작 전 로그도 `logs/backend/investment-choi.log`(및 로테이트 파일)에서 확인 가능. |
| **일일 백업(03:00)** | `register-log-backup-task.ps1` 등록 시 매일 새벽 `logs-backup/YYYYMMDD/backend.log` 생성. 재시작한 날 이전 날짜 폴더(예: 재시작 전날)를 열면 **재시작 전날까지의 스냅샷**으로 로그 확인 가능. |
| **재시작 전 수동 백업** | 재시작·재배포 전에 `.\scripts\backup-local-compose-logs.ps1` 실행 → 당일 `logs-backup/YYYYMMDD/backend.log` 에 그 시점까지의 전체 로그 저장. 이후 `docker compose up -d --force-recreate backend` 해도 백업 파일은 남음. |
| **중지된 컨테이너가 있을 때** | `docker ps -a` 에 Exited 인 이전 backend 컨테이너가 남아 있으면 `docker logs <container_id>` 로 해당 컨테이너 구간 로그 조회 가능. 단, `up -d --force-recreate` 또는 `down` 시 컨테이너가 제거되면 로그도 함께 삭제됨. |

---

## 4. 자동투자 “정상” 정의

- Backend 기동 후 `BatchJobScheduler`가 모든 cron Job을 등록하고, 해당 시간대에 launch → COMPLETED가 기록됨.
- **자동매수/파이프라인**이 실제로 주문을 넣으려면:
  - DB에 **자동투자 ON** 계좌 존재: `TradingSetting.autoTradingEnabled = true`.
  - (선택) 실주문: `investment.pipeline.auto-execute: true` 또는 계정별 `pipelineAutoExecute = true`.
- 배치 메타데이터 테이블 존재(Flyway V20+ 적용). 현재 로그상 “BATCH_JOB doesn't exist” 등 없음 → 정상.

---

## 5. 분석 체크리스트 (로그에서 확인할 항목)

| 구분 | 확인 항목 | 판단 |
|------|-----------|------|
| 기동 | Started InvestmentApplication, HikariPool Start completed | OK |
| 배치 테이블 | “doesn't exist”, “BATCH_JOB” 없음 | OK |
| 스케줄 등록 | “Scheduled batch job” (DEBUG) | OK |
| 매분/5분/10분 Job | fill-confirmation, unfilled-order-check, pipeline-exit, risk-event-alert launch → COMPLETED | OK |
| 자동매수(09:10) | 이번 기동은 14:59 시작이라 09:10 로그 없음. 필요 시 다음 09:10 또는 재시작 전 로그 확인 | 보류 |
| 외부 API | prediction-service, data-collector 5xx/타임아웃 없음 | OK |

---

## 6. 수정 개발 시: Shrimp Task Manager MCP 사용 (필수)

모든 수정·개발 작업은 **task 단위**로 Shrimp에서 관리한다.

1. **태스크 설계**: `plan_task`  
   - description: 목표·배경·예상 결과를 상세히 기입.  
   - 필요 시 requirements, existingTasksReference 사용.

2. **태스크 목록 확인**: `list_tasks`  
   - status: `all` / `pending` / `in_progress` / `completed` 로 진행 상황 파악.

3. **태스크 실행**: `execute_task`  
   - taskId: 실행할 작업의 UUID.  
   - 도구가 반환하는 단계별 지시를 따라 구현·검증.

4. **태스크 갱신/완료**: `update_task`, `verify_task`  
   - 내용·구현 가이드·검증 기준 보강, 완료 시 상태 반영.

**원인별 수정 시**:  
- Spring Batch 테이블 미존재 → Flyway/로컬 설정 문서 확인 태스크.  
- 자동투자 ON 계좌 없음 → 데이터/설정 확인(코드 수정 아님).  
- 파이프라인 dry run만 됨 → 설정(auto-execute) 점검 태스크.  
- Backend → prediction-service/data-collector 실패 → 네트워크/URL/재시도 개선 태스크.  
- 배치 Job 예외 → 해당 Job/서비스 수정 + 테스트 태스크.

각 항목을 **별도 Shrimp task**로 등록한 뒤 `execute_task`로 순차 진행한다.

---

## 7. 실행 순서 요약

1. **전체 로그 조회**: 위 3절 명령으로 각 서비스 **전체** 로그 수집 (200줄 제한 사용 금지).
2. **분석**: 5절 체크리스트와 2절 결과로 정상 여부 판단.
3. **이상 시**: 원인 특정 후 Shrimp에 `plan_task`로 태스크 등록 → `execute_task`로 수정 개발 → `update_task`/`verify_task`로 완료 처리.
4. **문서 반영**: [02-development-status.md](../../docs/09-planning/02-development-status.md), [13-manual-operator-tasks.md](../../investment-backend/docs/06-deployment/13-manual-operator-tasks.md) 등에 필요 시 요약 반영.

---

## 8. 결론 (이번 조회 기준)

- **재시작 전 로그**: 2.4절대로 복구 시도했으나, 이전 컨테이너 삭제·과거 날짜 백업 없음으로 **재시작(26일 14:59) 이전 구간은 분석 불가**. 아래 결론은 **재시작 이후 가용 로그만** 기준.
- **Backend**: 배치 스케줄 등록·매분/5분/10분 Job 실행 모두 COMPLETED. ERROR 없음. **정상**.
- **기타 컨테이너**: 기동·헬스·요청 처리 정상. **정상**.
- **자동매수(09:10) 실행 여부**: 이번 기동 구간에는 09:10 로그 없음. 다음부터는 **방법 B 볼륨** 적용으로 `logs/backend/` 에 이어서 쌓이므로, 재시작 후에도 09:10 구간 확인 가능. 일일 백업 등록 시 재시작 전날 스냅샷도 `logs-backup/전날날짜/` 에 남음.
- **수정 개발이 필요해지면**: 반드시 Shrimp Task Manager MCP로 task를 만들고, task 단위로 실행·검증한다.
